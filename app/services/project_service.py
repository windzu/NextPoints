from sqlmodel import Session
from fastapi import APIRouter, HTTPException, Depends, status
from collections import defaultdict
import posixpath
from pathlib import Path
import logging
from typing import Dict, Any, Optional, List,Set,Tuple
from botocore.exceptions import ClientError
from sqlmodel import select


from app.services.s3_service import S3Service
from app.models.project_model import Project,ProjectResponse,ProjectCreateRequest,ProjectStatus
from app.models.meta_data_model import FrameMetadata,CalibrationMetadata,ProjectMetadataResponse,Pose
from app.models.annotation_model import AnnotationItem,FrameAnnotation

from app.database import get_session

from tools.check_label import LabelChecker

logger = logging.getLogger(__name__)

def create_project(
    request: ProjectCreateRequest,
    session: Session = Depends(get_session)
) -> ProjectResponse:
    """
    åˆ›å»ºæ–°é¡¹ç›®å¹¶ä» S3 åŒæ­¥å¸§å’Œæ ‡å®šæ•°æ®ã€‚
    (Creates a new project and syncs frame and calibration data from S3.)
    """
    # 1. åˆå§‹åŒ–å¹¶æµ‹è¯• S3 è¿æ¥
    # (Initialize and test S3 connection)
    s3_service = S3Service(
        access_key_id=request.access_key_id,
        secret_access_key=request.secret_access_key,
        endpoint_url=request.s3_endpoint,
        region_name=request.region_name
    )
    
    success, message = s3_service.test_connection(request.bucket_name)
    if not success:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"S3 connection failed: {message}"
        )
    
    try:
        existing = session.exec(
            select(Project).where(Project.name == request.project_name)
        ).first()
        if existing:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Project with name '{request.project_name}' already exists."
            )


        # 2. åˆ›å»ºé¡¹ç›®è®°å½•
        # (Create the Project record)
        project = Project(
            name=request.project_name,
            description=request.description,
            storage_type=request.storage_type,
            storage_title=request.storage_title,
            bucket_name=request.bucket_name,
            bucket_prefix=request.bucket_prefix,
            region_name=request.region_name,
            s3_endpoint=request.s3_endpoint,
            access_key_id=request.access_key_id,
            secret_access_key=request.secret_access_key,
            use_presigned_urls=request.use_presigned_urls,
            expiration_minutes=request.expiration_minutes,
            status=ProjectStatus.unstarted,  # åˆå§‹çŠ¶æ€ä¸ºæœªå¼€å§‹
        )
        
        session.add(project)
        session.commit()
        session.refresh(project)

        # 3. use get_project_metadata to check project metadata
        get_project_metadata(project.name, session)

        # 4. return project response
        return ProjectResponse(
            id=project.id,
            name=project.name,
            description=project.description,
            status=project.status,
            created_at=project.created_at.isoformat(),  # ğŸ‘ˆ è½¬æˆå­—ç¬¦ä¸²
        )
    
    except Exception as e:
        # æ•è·å…¶ä»–æ‰€æœ‰å¼‚å¸¸ï¼ˆå¦‚æ•°æ®åº“é”™è¯¯ã€S3è¯»å–é”™è¯¯ï¼‰
        # (Catch all other exceptions, e.g., DB errors, S3 read errors)
        session.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"An unexpected error occurred during project creation: {e}"
        )

def get_project_metadata(
    project_name: str,
    session: Session = Depends(get_session)
) -> ProjectMetadataResponse:
    """
    è·å–é¡¹ç›®å®Œæ•´å…ƒæ•°æ®ã€‚ä¼˜å…ˆè¯»å–meta.jsonï¼Œè‹¥ä¸å­˜åœ¨åˆ™ç”Ÿæˆã€‚
    """
    # 1. è·å–é¡¹ç›®åŸºæœ¬ä¿¡æ¯å’ŒçŠ¶æ€
    project = session.exec(
        select(Project).where(Project.name == project_name)
    ).first()


    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # 2. åˆå§‹åŒ–S3æœåŠ¡
    s3_service = S3Service(
        access_key_id=project.access_key_id,
        secret_access_key=project.secret_access_key,
        endpoint_url=project.s3_endpoint,
        region_name=project.region_name
    )

    # 3. æ¯æ¬¡è·å–å…ƒæ•°æ®æ—¶éƒ½ç”Ÿæˆ meta.json
    # è¿™æ˜¯ä¸ºäº†ç¡®ä¿æ•°æ®æ˜¯æœ€æ–°çš„ï¼Œé¿å…ç¼“å­˜é—®é¢˜
    try:
        # meta_content = _generate_and_upload_meta_json(project, s3_service)
        project_meta_data = _generate_project_meta_data(project, s3_service)
        return project_meta_data
    except Exception as e:
        # æ•è·ç”Ÿæˆ meta.json æ—¶çš„ä»»ä½•å¼‚å¸¸
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to generate_project_meta_data: {str(e)}"
        )


def get_check_label(
    project_name: str,
    session: Session = Depends(get_session)
) -> List[Dict[str, Any]]:
    """
    è·å–é¡¹ç›®çš„æ ‡æ³¨æ£€æŸ¥æ•°æ®
    """
    try:
        # 1. è·å–é¡¹ç›®åŸºæœ¬ä¿¡æ¯å’ŒçŠ¶æ€
        project = session.exec(
            select(Project).where(Project.name == project_name)
        ).first()

        # 2. build FrameAnnotation list from label files
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        s3_service = S3Service(
            access_key_id=project.access_key_id,
            secret_access_key=project.secret_access_key,
            endpoint_url=project.s3_endpoint,
            region_name=project.region_name
        )
        label_key_prefix = str(Path(project.bucket_prefix or "") / "label")
        label_files = s3_service.list_objects(project.bucket_name, label_key_prefix)
        if not label_files:
            raise HTTPException(status_code=404, detail="No label files found for this project")
        annotations = []
        for label_file in label_files:
            key = label_file['key']
            relative_key = key[len(label_key_prefix):].lstrip('/') if label_key_prefix else key
            frame_id = Path(relative_key).stem  # è·å–å¸§ID
            
            try:
                annotation_data = s3_service.read_json_object(project.bucket_name, key)
                if not isinstance(annotation_data, list):
                    annotation_data = []  # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
                annotations.append(FrameAnnotation(
                    scene=project.name,
                    frame=frame_id,
                    annotation=[AnnotationItem(**item) for item in annotation_data]
                ))
            except Exception as e:
                logger.error(f"Failed to read or parse label file {key}: {e}")
                continue

        # 3. use LabelChecker to validate annotations
        label_checker = LabelChecker(annotations)
        label_checker.check()
        return label_checker.messages

    except Exception as e:
        logger.error(f"Failed to get label check data: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get label check data: {str(e)}"
        )

def save_world_list(
    request: List[FrameAnnotation],
    session: Session = Depends(get_session)
):
    """
    ä¿å­˜å•ä¸ªé¡¹ç›®çš„å¤šä¸ªä¸–ç•Œå¸§çš„æ ‡æ³¨æ•°æ®åˆ°S3å­˜å‚¨
    """

    try:
        if not request:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Request data cannot be empty"
            )

        # ç¡®ä¿æ‰€æœ‰æ¡ç›®çš„ scene ä¸€è‡´
        scenes = set(item.scene for item in request)
        if len(scenes) > 1:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"All frames must belong to the same project. Found: {list(scenes)}"
            )

        project_name = request[0].scene

        # è·å–é¡¹ç›®ä¿¡æ¯
        project = session.exec(
            select(Project).where(Project.name == project_name)
        ).first()

        if not project:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Project {project_name} not found"
            )

        # åˆå§‹åŒ– S3 æœåŠ¡
        s3_service = S3Service(
            access_key_id=project.access_key_id,
            secret_access_key=project.secret_access_key,
            endpoint_url=project.s3_endpoint,
            region_name=project.region_name
        )

        saved_count = 0

        # ä¿å­˜æ¯å¸§
        for item in request:
            try:
                prefix = project.bucket_prefix or ""
                if prefix and not prefix.endswith("/"):
                    prefix += "/"

                label_key = f"{prefix}label/{item.frame}.json"

                s3_service.upload_json_object(
                    bucket_name=project.bucket_name,
                    key=label_key,
                    data_dict=item.to_dict()["annotation"]
                )

                saved_count += 1

            except Exception as e:
                logger.error(f"Failed to save annotation for {project_name}/{item.frame}: {e}")
                logger.error(f"Annotation data: {item.annotation}")
                continue

        return {
            "message": f"Successfully saved {saved_count} annotations",
            "saved_count": saved_count,
            "total_requested": len(request)
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to save world list: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to save annotations: {str(e)}"
        )

def _generate_project_meta_data(
    project: Project,
    s3_service: S3Service,
    main_channel: Optional[str] = "lidar-fusion"
) -> ProjectMetadataResponse:
    """
    ç›®å½•çº¦å®šï¼ˆå‡åœ¨ root = bucket_prefix ä¸‹ï¼‰ï¼š
      - calib/<channel>.json
      - lidar/<lidar_channel>/<timestamp>.pcd
      - camera/<camera_channel>/<timestamp>.jpg
      - ego_pose/<timestamp>.json
    """
    def _safe_join(*parts: str, strip_slash=True) -> str:
        """
        å®‰å…¨æ‹¼æ¥ POSIX é£æ ¼è·¯å¾„ï¼Œè‡ªåŠ¨å»é™¤ç©ºå€¼å’Œå¤šä½™æ–œæ ã€‚
        
        Args:
            *parts: è·¯å¾„ç‰‡æ®µï¼ˆå¯ä»¥åŒ…å«ç©ºå­—ç¬¦ä¸²æˆ– Noneï¼‰
            strip_slash: æ˜¯å¦å»æ‰æ¯ä¸ªç‰‡æ®µçš„é¦–å°¾æ–œæ ï¼ˆé»˜è®¤ Trueï¼‰
        
        Returns:
            æ‹¼æ¥åçš„è·¯å¾„å­—ç¬¦ä¸²
        """
        cleaned_parts = []
        for p in parts:
            if not p:  # è¿‡æ»¤ None / ç©ºå­—ç¬¦ä¸²
                continue
            if strip_slash:
                p = p.strip("/")  # å»æ‰é¦–å°¾æ–œæ ï¼Œé¿å…é‡å¤
            cleaned_parts.append(p)
        
        return posixpath.join(*cleaned_parts)

    def _stem(filename: str) -> str:
        """è¿”å›å»æ‰©å±•ååçš„æ–‡ä»¶å"""
        base = filename.rsplit("/", 1)[-1]
        return base.rsplit(".", 1)[0] if "." in base else base

    def _is_ext(key: str, *exts: str) -> bool:
        k = key.lower()
        return any(k.endswith(e.lower()) for e in exts)

    def _ns_to_int(ts_ns: str) -> int:
        return int(ts_ns)

    def _project_to_response(project: Project) -> ProjectResponse:
        return ProjectResponse(
            id=project.id,
            name=project.name,
            description=project.description,
            status=ProjectStatus(project.status),
            created_at=project.created_at.isoformat(),
        )

    def _as_url(s3: S3Service, project: Project, bucket_key: str) -> str:
        """å¦‚éœ€ URLï¼Œå¯ç”¨è¯¥å‡½æ•°æ›¿æ¢ _as_key çš„è°ƒç”¨"""
        return s3.get_object_url(
            bucket_name=project.bucket_name,
            object_key=bucket_key,
            use_presigned=project.use_presigned_urls,
            expiration=project.expiration_minutes * 60,
        )


    bucket = project.bucket_name
    root = _safe_join(project.bucket_prefix or "")

    calib_prefix   = _safe_join(root, "calib")
    lidar_prefix   = _safe_join(root, "lidar")
    camera_prefix  = _safe_join(root, "camera")
    ego_pose_prefix= _safe_join(root, "ego_pose")

    # 1) è¯» calibï¼šä¸¥æ ¼æ ¡éªŒä¸º CalibrationMetadata
    calibration: Dict[str, CalibrationMetadata] = {}
    for obj in s3_service.list_all_objects(bucket, calib_prefix):
        key = obj.get("Key") or obj.get("key")
        if not key or not _is_ext(key, ".json"):
            continue
        raw = s3_service.read_json_object(bucket, key)
        meta = CalibrationMetadata.model_validate(raw)  # ä¸ä¸€è‡´ç›´æ¥æŠ›é”™
        chan = meta.channel or _stem(key)  # ä»¥ JSON å†… channel ä¸ºå‡†ï¼Œç¼ºå¤±åˆ™ç”¨æ–‡ä»¶å
        # å¦‚éœ€é˜²æ­¢é‡å¤ channel ç›´æ¥æŠ¥é”™ï¼Œå¯å¯ç”¨ä»¥ä¸‹æ£€æŸ¥
        # if chan in calibration:
        #     raise ValueError(f"é‡å¤çš„ calibration channel: {chan}")
        calibration[chan] = meta

    # 2) æšä¸¾ lidar/camera å­é€šé“åŠå„è‡ªçš„æ—¶é—´æˆ³ç´¢å¼•
    lidar_channels: Dict[str, Set[str]] = {}   # channel -> {timestamp_ns}
    lidar_index: Dict[Tuple[str, str], str] = {}  # (channel, ts) -> key

    for obj in s3_service.list_all_objects(bucket, lidar_prefix):
        key = obj.get("Key") or obj.get("key")
        if not key or not _is_ext(key, ".pcd"):
            continue
        # ç»“æ„ï¼šlidar/<channel>/<timestamp>.pcd
        rel = key[len(lidar_prefix):].lstrip("/")  # <channel>/<file>
        if "/" not in rel:
            # å¿½ç•¥ä¸è§„èŒƒ
            continue
        channel, fname = rel.split("/", 1)
        ts = _stem(fname)
        lidar_channels.setdefault(channel, set()).add(ts)
        lidar_index[(channel, ts)] = key

    camera_channels: Dict[str, Set[str]] = {}
    camera_index: Dict[Tuple[str, str], str] = {}

    for obj in s3_service.list_all_objects(bucket, camera_prefix):
        key = obj.get("Key") or obj.get("key")
        if not key or not _is_ext(key, ".jpg", ".jpeg", ".png"):
            continue
        # ç»“æ„ï¼šcamera/<channel>/<timestamp>.<ext>
        rel = key[len(camera_prefix):].lstrip("/")
        if "/" not in rel:
            continue
        channel, fname = rel.split("/", 1)
        ts = _stem(fname)
        camera_channels.setdefault(channel, set()).add(ts)
        camera_index[(channel, ts)] = key

    # ego_poseï¼šts -> key
    ego_pose_index: Dict[str, str] = {}
    for obj in s3_service.list_all_objects(bucket, ego_pose_prefix):
        key = obj.get("Key") or obj.get("key")
        if not key or not _is_ext(key, ".json"):
            continue
        ts = _stem(key)
        if "/" in ts:
            ts = _stem(ts.split("/")[-1])
        ego_pose_index[ts] = key

    if not lidar_channels:
        raise ValueError("æœªåœ¨ lidar/ ç›®å½•ä¸‹å‘ç°ä»»ä½•æ¿€å…‰é€šé“æ•°æ®ã€‚")

    # 3) é€‰æ‹© main_channel
    def pick_main_channel() -> str:
        if main_channel in lidar_channels:
            return main_channel
        if len(lidar_channels) == 1:
            return next(iter(lidar_channels.keys()))
        return sorted(lidar_channels.keys())[0]

    main_channel = pick_main_channel()
    baseline_ts = sorted(lidar_channels[main_channel], key=lambda x: _ns_to_int(x))

    if not baseline_ts:
        raise ValueError(f"ä¸»é€šé“ {main_channel} ä¸‹æœªå‘ç°ä»»ä½• .pcd å¸§ã€‚")

    # 4) æ„å»º framesï¼šä»¥ä¸»é€šé“æ—¶é—´æˆ³ä½œä¸ºå¸§é›†åˆ
    frames: List[FrameMetadata] = []
    for idx, ts in enumerate(baseline_ts):
        # lidars: æ”¶é›†åŒæ—¶é—´æˆ³çš„æ‰€æœ‰æ¿€å…‰é€šé“ï¼ˆè‡³å°‘åŒ…å« main_channelï¼‰
        lidars: Dict[str, str] = {}
        for ch in lidar_channels.keys():
            key = lidar_index.get((ch, ts))
            if key:
                lidars[ch] = _as_url(s3_service, project, key)
        if main_channel not in lidars:
            # æŒ‰ç†ä¸ä¼šå‘ç”Ÿï¼ˆbaseline æ¥æºäº main_channelï¼‰ï¼Œä¸¥é˜²ä¸€è‡´æ€§é—®é¢˜
            raise ValueError(f"æ—¶é—´æˆ³ {ts} ç¼ºå°‘ä¸»é€šé“ {main_channel} çš„ç‚¹äº‘ã€‚")

        # images: æ”¶é›†åŒæ—¶é—´æˆ³çš„æ‰€æœ‰ç›¸æœºå›¾ç‰‡ï¼ˆå¯ç©ºï¼‰
        images: Dict[str, str] = {}
        for ch in camera_channels.keys():
            key = camera_index.get((ch, ts))
            if key:
                images[ch] = _as_url(s3_service, project, key)

        # ego poseï¼šå¯ç©ºï¼›è‹¥å­˜åœ¨ä¸¥æ ¼æ ¡éªŒä¸º Pose
        pose: Optional[Pose] = None
        pose_key = ego_pose_index.get(ts)
        if pose_key:
            pose_raw = s3_service.read_json_object(bucket, pose_key)
            pose = Pose.model_validate(pose_raw)  # ä¸ä¸€è‡´ç›´æ¥æŠ›é”™

        prev_ts = baseline_ts[idx - 1] if idx > 0 else ""
        next_ts = baseline_ts[idx + 1] if idx < len(baseline_ts) - 1 else ""

        # annotation: å¯ç©ºï¼›è‹¥å­˜åœ¨ä¸¥æ ¼æ ¡éªŒä¸º AnnotationItem åˆ—è¡¨
        annotation: Optional[List[AnnotationItem]] = None
        label_key = _safe_join(root, "label", f"{ts}.json")
        try:
            label_data = s3_service.read_json_object(bucket, label_key)
            if isinstance(label_data, list):
                annotation = [AnnotationItem.model_validate(item) for item in label_data]
            else:
                raise ValueError(f"æ ‡æ³¨æ•°æ® {label_key} æ ¼å¼é”™è¯¯ï¼Œåº”ä¸ºåˆ—è¡¨ã€‚")
        except ClientError as e:
            if e.response['Error']['Code'] == 'NoSuchKey':
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶ï¼Œåˆ™ annotation ä¸ºç©º
                annotation = None
            else:
                raise ValueError(f"è¯»å–æ ‡æ³¨æ–‡ä»¶ {label_key} å¤±è´¥: {e}")

        frames.append(
            FrameMetadata(
                id=idx,  # è¿ç»­ç¼–å·
                timestamp_ns=ts,
                prev_timestamp_ns=prev_ts,
                next_timestamp_ns=next_ts,
                lidars=lidars,
                images=images or None,
                pose=pose,
                annotation=annotation,
            )
        )

    # 5) æ‘˜è¦
    start_ts = baseline_ts[0]
    end_ts = baseline_ts[-1]
    duration_seconds = max(0.0, (_ns_to_int(end_ts) - _ns_to_int(start_ts)) / 1e9)


    project_meta_response = ProjectMetadataResponse(
        project=_project_to_response(project),
        frame_count=len(frames),
        start_timestamp_ns=start_ts,
        end_timestamp_ns=end_ts,
        duration_seconds=duration_seconds,
        main_channel=main_channel,
        calibration=calibration,
        frames=frames,
    )

    # 6) ç»„è£…è¿”å›
    return project_meta_response
